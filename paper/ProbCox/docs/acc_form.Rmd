---
title: "Author Contributions Checklist "
author: Alexander Wolfgang Jung
date: May 18, 2021
output: pdf_document
bibliography: probcox.bib
---

<!--HOW TO COMPLETE THIS FORM:-->

<!--
1. Checkboxes in this document appear as follows:

- [ ] This is a checkbox

To check a checkbox, replace [ ] by [x], as follows:

- [x] This is a checked checkbox

Note that current versions of RStudio for Mac (this will change with RStudio versions 1.3 and higher) will not create a formatted checkbox but will leave the original characters, i.e., literally "[ ]" or "[x]". It's fine to submit a PDF in this form.

2. For text answers, simply type the relevant text in the areas indicated. A blank line starts a new paragraph.

3. Comments (like these instructions) provide additional instructions throughout the form. There is no need to remove them; they will not appear in the compiled document.

4. If you are comfortable with Markdown syntax, you may choose to include any Markdown-compliant formatting in the form. For example, you may wish to include R code chunks and compile this document in R Markdown.
-->

This form documents the artifacts associated with the article (i.e., the data and code supporting the computational findings) and describes how to reproduce the findings.

# Part 1: Data

- [ ] This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code).

<!--
If box above is checked and if no simulated/synthetic data files are provided by the authors, please skip directly to the Code section. Otherwise, continue.
-->

- [X] I certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.

<!-- If data are simulated using random number generation, please be sure to set the random number seed in the code you provide -->

## Abstract

**Publicly Available:**
We analyzed a small number of dataset provided in the R-Survival [@therneau_package_2015] package.
These include:
- Colon are data on trials of adjuvant chemotherapy for colon cancer,  [@laurie_surgical_1989].
- Lung are data extracted from the North Central Cancer Treatment Group on mortality for advanced lung cancer [@loprinzi_prospective_1994].
- NAFLD is a large population-based study investigating non-alcoholic fatty liver disease (NAFLD) [@allen_nonalcoholic_2018].
- Heart investigates mortality in patients from the Stanford heart transplant program [@crowley_covariance_1977]
The purpose of these examples is to evaluate the performance of our proposed method in comparison to the frequentist Cox model on real world applications.

**Non-publicly available:**
The UK Biobank (UKB) [@sudlow_uk_2015] is a large-scale biomedical database established in 2006. In total there are 502628 participants, recruited between 2006 and 2010. All participants were between 40-69 years of age at their recruitment date. We study the association of standard risk factors and comorbidities, taken from the electronic health records, with the occurrence of myocardial infarction. For details of the analysis see section 4 of the paper.

## Availability
- [X] Partial Data **are** publicly available.
- [X] Partial Data **cannot be made** publicly available.

### Publicly available data

- [X] Data are available online at: https://github.com/alexwjung/ProbCox

- [X] Data are available as part of the paperâ€™s supplementary material.

- [ ] Data are publicly available by request, following the process described here:

- [ ] Data are or will be made available through some other mechanism, described here:


<!-- If data are available by request to the authors or some other data owner, please make sure to explain the process of requesting access to the data. -->

### Non-publicly available data

<!--
The Journal of the American Statistical Association requires authors to make data accompanying their papers available to the scientific community except in cases where: 1) public sharing of data would be impossible, 2) suitable synthetic data are provided which allow the main analyses to be replicated (recognizing that results may differ from the "real" data analyses), and 3) the scientific value of the results and methods outweigh the lack of reproducibility.

Please discuss the lack of publicly available data. For example:
-	why data sharing is not possible,
-	what synthetic data are provided, and
-	why the value of the paper's scientific contribution outweighs the lack of reproducibility.
-->
The UK-Biobank (UKB) data contains sensible information on individuals and cannot be openly shared for privacy considerations.
However, researchers can apply for access to the UKB under:
https://www.ukbiobank.ac.uk/enable-your-research/apply-for-access

The simulation study we present in the paper closely resembles the data structure encountered in electronic health records, similar to the data in the UKB, and can be used as a guidance.
We also additionally provide a small simulation reflecting the analysis in the UKB.

Electronic health records and biobanks contain a vast array of information on individuals that open new possibilities to study disease and are therefore highly important in biomedical research. However, the wealth of information also makes it difficult to obfuscate data in such a way as to preserve important structures in the data.
This inevitably leads to issue for openly distributing the data.

## Description
The data provided can be found in [Data](./data)

The fake data resembling the analysis in the UKB can be created with (./replication/UKB/00_fakedata.ipynb)

### File format(s)

<!--
Check all that apply
-->
- [X] CSV or other plain text.
- [ ] Software-specific binary format (.Rda, Python pickle, etc.): pkcle
- [X] Standardized binary format (e.g., netCDF, HDF5, etc.):
- [ ] Other (please specify):

### Data dictionary

<!--
A data dictionary provides information that allows users to understand the meaning, format, and use of the data.
-->

- [ ] Provided by authors in the following file(s):
- [X] Data file(s) is(are) self-describing (e.g., netCDF files)
- [ ] Available at the following URL:

### Additional Information (optional)

-

# Part 2: Code

## Abstract

We provide a python package (probcox) for the implemented method. This is a scalable version of the Cox model fitted via stochastic variational inference. The code is written entirely in pytorch/pyro and numpy.
We provide an algorithm to efficiently simulate survival times with time-varying covariates that resemble disease association studies in electronic health records.
The original scripts for all the analyses are provided. Additionally, there are jupyter notebooks that can be run in google colab to readily replicate all of the results presented (except for the UKB as we cannot provide the data as mentioned above). However, we do provide a similar replicated analysis for the UKB, based on a simulated dataset.

## Description
### Code format(s)
<!--
Check all that apply
-->
- [ ] Script files
    - [X] R
    - [X] Python
    - [ ] Matlab
    - [ ] Other:
- [ ] Package
    - [X] R
    - [X] Python
    - [ ] MATLAB toolbox
    - [ ] Other:
- [ ] Reproducible report
    - [ ] R Markdown
    - [X] Jupyter notebook
    - [X] Other: Google Colab
- [X] Shell script
- [ ] Other (please specify):

### Supporting software requirements

We provide replicable notebooks that can be used with Google Colab (requirement: Google account).
The notebooks can also be run via local jupyter notebooks.

#### Version of primary software used

Python version 3.7

R version 4.0.3

#### Libraries and dependencies used by the code

We use conda [https://docs.conda.io/en/latest/] as a package manager and the full list of install packages can be found/replicated via [R environment](./docs/requirements_R.txt) and [Python environment](./docs/requirements_python.txt), respectively.

When probcox is installed via pip it installs most of the required packages automatically (assuming a basic python install: numpy, pandas, matplotlib, h5py, tqdm).

### Supporting system/hardware requirements (optional)

<!--
OPTIONAL: System/hardware requirements including operating system with version number, access to cluster, GPUs, etc.
-->
We had access to a cluster to run the simulations. The main purpose for this was to run simulations simultaneously.
The proposed package - automatically adapts to the underlying hardware and parallelizes computation where possible.

### Parallelization used

- [ ] No parallel code used
- [X] Multi-core parallelization on a single machine/node
    - Number of cores used: varying - can be adjusted by user - will be clear in scripts.
- [ ] Multi-machine/multi-node parallelization
    - Number of nodes and cores used:

### License

- [X] MIT License (default)
- [ ] BSD
- [ ] GPL v3.0
- [ ] Creative Commons
- [ ] Other: (please specify below)


### Additional information (optional)

The code for the model can be installed via:

```
$ pip install probcox
```

## Scope

The provided workflow reproduces:

- [X] Any numbers provided in text in the paper
- [X] All tables and figures in the paper
- [ ] Selected tables and figures in the paper, as explained and justified below:

## Workflow
### Format(s)

<!--
Check all that apply
-->
- [ ] Single master code file
- [ ] Wrapper (shell) script(s)
- [ ] Self-contained R Markdown file, Jupyter notebook, or other literate programming approach
- [ ] Text file (e.g., a readme-style file) that documents workflow
- [ ] Makefile
- [X] Other (more detail in *Instructions* below)

### Instructions
<!--
Describe how to use the materials provided to reproduce analyses in the manuscript. Additional details can be provided in file(s) accompanying the reproducibility materials.
-->
We assume that individuals have an google account and can run the notebooks via google colabs. The replication can similarly be run on a local installation with jupyter notebooks.

The original scripts used to run the analyses, and most of the raw outputs ect. can be found in this folder.
We mainly distinguish between application (similarly named as the used data) and simulations, where standard cases may be shortened to sim_sc and high dimensional case to sim_hd.

- The accompanying data can be found in [Data](./data)
- Information on the installed packages, the Author Contributions Checklist, and other relevant documents are found in [Docs](./docs)
- Most of the outputs and raw files, like estimates, tables, figures etc. are found in [Out](./out)
- A dedicated folder with the relevant outputs for the paper can be found in [Paper](./paper)
- The scripts used to run the analysis is found in [Scripts](./scripts)
- A dedicated folder for the analysis of the UKB data with subfolder [output](./ukb/out) and [scripts](./ukb/scripts) can be found in [UKB-Analysis](./ukb)

Notebooks for easy replication of the analysis can be found in [Replication](./replication)


Link to the .ipynb files - link to a specific colab session


- Replication for the applications are in [Replicate Applications](./replication/application)
    - [Colon](./replication/application/colon.ipynb) - [Colab](https://colab.research.google.com/drive/1HifKMp2SjKB3NCnNe-vD1EiAf2bQQ7Rp?usp=sharing)
    - [Lung](./replication/application/lung.ipynb) - [Colab](https://colab.research.google.com/drive/1IniSnT1bUINtUnu_owezJ0FWeKyXWgvu?usp=sharing)
    - [Heart](./replication/application/heart.ipynb) - [Colab](https://colab.research.google.com/drive/1bXWSxZA4KvRvxi5xZswDPbdIEaPTrljv?usp=sharing)
    - [Nafld](./replication/application/nafld.ipynb) - [Colab](https://colab.research.google.com/drive/13IJLUfXSqF_3U9dsEBuvo-Vy29r7WLzn?usp=sharing)
    - [PBCseq](./replication/application/pbcseq.ipynb) - [Colab](https://colab.research.google.com/drive/15Y9XK5YlldRgpha7D0aT9eMmpMN_JxLu?usp=sharing)


- Replication for the simulations are in [Replicate Simulations](./replication/simulations)
    - [Standard Case 1](./replication/simulation/standard_case1.ipynb) - [Colab](https://colab.research.google.com/drive/1iEoO9hHkgRWzaLhbU9VYhYk6U6V8nffG?usp=sharing)
    - [Standard Case 2](./replication/simulation/standard_case2.ipynb) - [Colab](https://colab.research.google.com/drive/1lIm7d866QtbIxqY6IRhIFrfTECLBWSDn?usp=sharing)
    - [High-dimensional Case](./replication/simulation/highdimensional_case.ipynb) - [Colab](https://colab.research.google.com/drive/1Db9x78fYhhj5yVTalMhKsP6wOm9tArKr?usp=sharing)

- To replicate the tables presented in the paper go to [Replicate Tables](./replication/tables)
    - [Data Example](./replication/simulation/tables/data_example.ipynb) - [Colab](https://colab.research.google.com/drive/1yHM5iDRE0GqTsj7Jpql32PjpNJaopSJX?usp=sharing)
    - [Likelihood Approximation](./replication/simulation/tables/likelihood_approx.ipynb) - [Colab](https://colab.research.google.com/drive/1HJeGSiSX6_plwbgJleY4RjYFa13Gm2O-?usp=sharing)
    - [Likelihood Approximation - large P](./replication/simulation/tables/likelihood_approx_additional1.ipynb) - [Colab](https://colab.research.google.com/drive/1USX1g8PmHkm6Di1WiwAV0u9nJdZ1JtPw?usp=sharing)
    - [Likelihood Approximation- large LP](./replication/simulation/tables/likelihood_approx_additional2.ipynb) - [Colab](https://colab.research.google.com/drive/1Kx2y_E4aSLx6AG0rlQd3pKDJ2F6HR-_f?usp=sharing)
    - [Standard Case 1](./replication/simulation/tables/standard_case1_table.ipynb) - [Colab](https://colab.research.google.com/drive/11XX0E36TUTNnTFhEeW-It7YIm-5vKc4q?usp=sharing)
    - [Standard Case 2](./replication/simulation/tables/standard_case2_table.ipynb) - [Colab](https://colab.research.google.com/drive/13Pt2tMoJAKkgpU-L9KmqWj-tgsgQNBaz?usp=sharing)
    - [High-dimensional Case](./replication/simulation/tables/highdimensional_case_table.ipynb) - [Colab](https://colab.research.google.com/drive/1Uj6lQaivKj7UaEgR-j5feZgXFhXke0R1?usp=sharing)

- To replicate the figures presented in the paper go to [Replicate Figures](./replication/figures)
    - [Schematic](./replication/simulation/figures/schematic.ipynb) - [Colab](https://colab.research.google.com/drive/1Hz1IG6z4fOJBTNEIM6jSnyO6l586P3G1?usp=sharing)
    - [Likelihood Approximation over training](./replication/simulation/figures/likelihood_training.ipynb) - [Colab](https://colab.research.google.com/drive/1kz42UvTAag7XxEWCgMhw6GidP_fuwW4p?usp=sharing)
    - [High-dimensional](./replication/simulation/figures/hd.ipynb) - [Colab](https://colab.research.google.com/drive/1i_NbMRESZTNSHsqRlnRu0GuPA658UT9W?usp=sharing)
    - [Baseline Hazard](./replication/simulation/figures/) - [Colab](https://colab.research.google.com/drive/1PDp2G-ob1tjIlnh03j9TyoH7QlxDuGYM?usp=sharing)

- To replicate a similar analysis as in the UKB go to [Replicate Fake UKB](./replication/ukb)
        - [Fake Data Generation](./replication/ukb/00_fakedata.ipynb) - [Colab](https://colab.research.google.com/drive/1wT4pw2WEk6npzx7lrSaOjo5JUwTEfVXr?usp=sharing)
        - [Analysis](./replication/ukb/01_fakeanalysis.ipynb) - [Colab](https://colab.research.google.com/drive/1dP4TCF12Nx50bgn7GA2YkBNo9fAFbD2M?usp=sharing)


### Expected run-time

Approximate time needed to reproduce the analyses on a standard desktop machine:

- [ ] < 1 minute
- [ ] 1-10 minutes
- [ ] 10-60 minutes
- [X] 1-8 hours
- [ ] > 8 hours
- [ ] Not feasible to run on a desktop machine, as described here:

### Additional information (optional)

- Rerunning all the simulations on a single desktop machine will take a considered amount of time. We therefore provide individual simualtion runs (choosen by demand) that can be checked/compared to the results provided on https://github.com/alexwjung/ProbCox.

- The simulation results for the high-dimensional case can suffer from numerical instabilities, this happens for the the particular prior specification of student(nu=1, s=0.001). With s > 0.01 we find the result to stabalize much better, however, there is also a stonger regularization applied.
Our replication results are not exact, however, differences are marginal and the overall result are the same.

- The fake simulation for the UKB data needs to write ~2GB of data. In the colab notebooks this would need to be written to the google drive.
# Notes (optional)

# References
